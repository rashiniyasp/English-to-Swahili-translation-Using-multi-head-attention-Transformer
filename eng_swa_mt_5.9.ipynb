{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T22:19:52.106174Z",
     "iopub.status.busy": "2025-02-23T22:19:52.105227Z",
     "iopub.status.idle": "2025-02-23T22:20:03.804873Z",
     "shell.execute_reply": "2025-02-23T22:20:03.804146Z",
     "shell.execute_reply.started": "2025-02-23T22:19:52.106107Z"
    },
    "papermill": {
     "duration": 12.578941,
     "end_time": "2024-03-24T02:42:51.721672",
     "exception": false,
     "start_time": "2024-03-24T02:42:39.142731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "\n",
    "import tensorflow as tf\n",
    "import string\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T22:20:03.806762Z",
     "iopub.status.busy": "2025-02-23T22:20:03.806279Z",
     "iopub.status.idle": "2025-02-23T22:20:04.121672Z",
     "shell.execute_reply": "2025-02-23T22:20:04.119952Z",
     "shell.execute_reply.started": "2025-02-23T22:20:03.806732Z"
    },
    "papermill": {
     "duration": 0.257149,
     "end_time": "2024-03-24T02:42:51.990866",
     "exception": false,
     "start_time": "2024-03-24T02:42:51.733717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.16.1\n",
      "\n",
      "GPU is AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print()\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"AVAILABLE\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T22:20:04.123229Z",
     "iopub.status.busy": "2025-02-23T22:20:04.122836Z",
     "iopub.status.idle": "2025-02-23T22:20:04.728510Z",
     "shell.execute_reply": "2025-02-23T22:20:04.727778Z",
     "shell.execute_reply.started": "2025-02-23T22:20:04.123181Z"
    },
    "papermill": {
     "duration": 0.587422,
     "end_time": "2024-03-24T02:42:52.638078",
     "exception": false,
     "start_time": "2024-03-24T02:42:52.050656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the correct file path\n",
    "file_path = \"/kaggle/input/nlp-cleaned/english_swahili_sentence_pairs_cleaned.csv\"\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T22:20:04.730395Z",
     "iopub.status.busy": "2025-02-23T22:20:04.730116Z",
     "iopub.status.idle": "2025-02-23T22:20:04.746446Z",
     "shell.execute_reply": "2025-02-23T22:20:04.745588Z",
     "shell.execute_reply.started": "2025-02-23T22:20:04.730367Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English sentence</th>\n",
       "      <th>Swahili Translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am.</td>\n",
       "      <td>Mimi ni.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Him.</td>\n",
       "      <td>Yeye.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Her.</td>\n",
       "      <td>Yeye.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You.</td>\n",
       "      <td>Wewe.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We.</td>\n",
       "      <td>Sisi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198953</th>\n",
       "      <td>The national army safeguards the country's bor...</td>\n",
       "      <td>Jeshi la kitaifa linalinda mpaka wa nchi hiyo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198954</th>\n",
       "      <td>I participated in last year's motor rally cham...</td>\n",
       "      <td>Nilishiriki katika mashindano ya rally ya moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198955</th>\n",
       "      <td>This court mainly deals with crimes committed ...</td>\n",
       "      <td>Korti hii inashughulikia uhalifu uliofanywa na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198956</th>\n",
       "      <td>The company terminated their contract yesterday.</td>\n",
       "      <td>Kampuni hiyo ilisitisha mkataba wao jana.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198957</th>\n",
       "      <td>The ministry of health has posted five health ...</td>\n",
       "      <td>Wizara ya afya imeweka wafanyikazi watano wa a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198958 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         English sentence  \\\n",
       "0                                                   I am.   \n",
       "1                                                    Him.   \n",
       "2                                                    Her.   \n",
       "3                                                    You.   \n",
       "4                                                     We.   \n",
       "...                                                   ...   \n",
       "198953  The national army safeguards the country's bor...   \n",
       "198954  I participated in last year's motor rally cham...   \n",
       "198955  This court mainly deals with crimes committed ...   \n",
       "198956   The company terminated their contract yesterday.   \n",
       "198957  The ministry of health has posted five health ...   \n",
       "\n",
       "                                      Swahili Translation  \n",
       "0                                                Mimi ni.  \n",
       "1                                                   Yeye.  \n",
       "2                                                   Yeye.  \n",
       "3                                                   Wewe.  \n",
       "4                                                   Sisi.  \n",
       "...                                                   ...  \n",
       "198953  Jeshi la kitaifa linalinda mpaka wa nchi hiyo ...  \n",
       "198954  Nilishiriki katika mashindano ya rally ya moto...  \n",
       "198955  Korti hii inashughulikia uhalifu uliofanywa na...  \n",
       "198956          Kampuni hiyo ilisitisha mkataba wao jana.  \n",
       "198957  Wizara ya afya imeweka wafanyikazi watano wa a...  \n",
       "\n",
       "[198958 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T22:20:04.747855Z",
     "iopub.status.busy": "2025-02-23T22:20:04.747613Z",
     "iopub.status.idle": "2025-02-23T22:20:04.838156Z",
     "shell.execute_reply": "2025-02-23T22:20:04.837247Z",
     "shell.execute_reply.started": "2025-02-23T22:20:04.747829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           source  \\\n",
      "16219  This is years since his valve replacement.   \n",
      "69321                           He meant no harm.   \n",
      "53267                          Bulgaria road map.   \n",
      "73672                          Tom works at home.   \n",
      "92821                    Do you think i'm stupid?   \n",
      "\n",
      "                                                  target  \n",
      "16219  [start] Hii ni miaka tangu uingizwaji wake wa ...  \n",
      "69321            [start] Alimaanisha hakuna ubaya. [end]  \n",
      "53267      [start] Ramani ya barabara ya bulgaria. [end]  \n",
      "73672          [start] Tom anafanya kazi nyumbani. [end]  \n",
      "92821            [start] Unafikiri mimi ni mjinga? [end]  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Add 'source' and 'target' columns\n",
    "df['source'] = df['English sentence']\n",
    "df['target'] = df['Swahili Translation'].apply(lambda x: '[start] ' + x + ' [end]')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df = df.drop(['English sentence', 'Swahili Translation'], axis=1)\n",
    "\n",
    "# Display a few random samples\n",
    "print(df.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T22:20:04.840190Z",
     "iopub.status.busy": "2025-02-23T22:20:04.839384Z",
     "iopub.status.idle": "2025-02-23T22:20:04.848454Z",
     "shell.execute_reply": "2025-02-23T22:20:04.847655Z",
     "shell.execute_reply.started": "2025-02-23T22:20:04.840143Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am.</td>\n",
       "      <td>[start] Mimi ni. [end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Him.</td>\n",
       "      <td>[start] Yeye. [end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Her.</td>\n",
       "      <td>[start] Yeye. [end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You.</td>\n",
       "      <td>[start] Wewe. [end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We.</td>\n",
       "      <td>[start] Sisi. [end]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source                  target\n",
       "0  I am.  [start] Mimi ni. [end]\n",
       "1   Him.     [start] Yeye. [end]\n",
       "2   Her.     [start] Yeye. [end]\n",
       "3   You.     [start] Wewe. [end]\n",
       "4    We.     [start] Sisi. [end]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011793,
     "end_time": "2024-03-24T02:42:52.662393",
     "exception": false,
     "start_time": "2024-03-24T02:42:52.6506",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "SPLITTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T22:20:04.849737Z",
     "iopub.status.busy": "2025-02-23T22:20:04.849468Z",
     "iopub.status.idle": "2025-02-23T22:20:05.096221Z",
     "shell.execute_reply": "2025-02-23T22:20:05.095162Z",
     "shell.execute_reply.started": "2025-02-23T22:20:04.849711Z"
    },
    "papermill": {
     "duration": 0.233867,
     "end_time": "2024-03-24T02:42:52.908213",
     "exception": false,
     "start_time": "2024-03-24T02:42:52.674346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# shuffle the data\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# split the data into train, validation, and test sets\n",
    "train_size = int(len(df) * 0.7)\n",
    "val_size = int(len(df) * 0.2)\n",
    "test_size = int(len(df) * 0.1)\n",
    "\n",
    "train_df = df[:train_size]\n",
    "val_df = df[train_size:train_size+val_size]\n",
    "test_df = df[train_size+val_size:]\n",
    "\n",
    "# display the data sets representations using a pie chart just to see the distribution of the data\n",
    "labels = 'Train', 'Validation', 'Test'\n",
    "sizes = [len(train_df), len(val_df), len(test_df)]\n",
    "explode = (0.1, 0, 0)\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "ax1.axis('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012699,
     "end_time": "2024-03-24T02:42:52.933796",
     "exception": false,
     "start_time": "2024-03-24T02:42:52.921097",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T22:20:05.098048Z",
     "iopub.status.busy": "2025-02-23T22:20:05.097599Z",
     "iopub.status.idle": "2025-02-23T22:20:06.944892Z",
     "shell.execute_reply": "2025-02-23T22:20:06.943876Z",
     "shell.execute_reply.started": "2025-02-23T22:20:05.097996Z"
    },
    "papermill": {
     "duration": 1.41359,
     "end_time": "2024-03-24T02:42:54.384844",
     "exception": false,
     "start_time": "2024-03-24T02:42:52.971254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_tokens = 25000\n",
    "sequence_length = 30\n",
    "\n",
    "# define a custom standardization function that convert to lowercase and strips all punctuations except \"[\" and \"]\" (so we can tell apart \"start\" from \"[start]\").\n",
    "strip_chars = string.punctuation\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    " \n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(\n",
    "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
    "\n",
    "# tokenize the data using our custom standardization function\n",
    "source_vectorization = keras.layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "target_vectorization = keras.layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length + 1, # add +1 token to our target sentences since they'll be shifted right by 1 during training\n",
    "    standardize=custom_standardization,\n",
    ")\n",
    "\n",
    "# index all tokens in the source and target sentences\n",
    "train_source_texts = train_df['source'].values\n",
    "train_target_texts = train_df['target'].values\n",
    "source_vectorization.adapt(train_source_texts)\n",
    "target_vectorization.adapt(train_target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T22:20:06.946567Z",
     "iopub.status.busy": "2025-02-23T22:20:06.946257Z",
     "iopub.status.idle": "2025-02-23T22:20:12.116196Z",
     "shell.execute_reply": "2025-02-23T22:20:12.115271Z",
     "shell.execute_reply.started": "2025-02-23T22:20:06.946538Z"
    },
    "papermill": {
     "duration": 6.609412,
     "end_time": "2024-03-24T02:43:01.010105",
     "exception": false,
     "start_time": "2024-03-24T02:42:54.400693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source texts (one random sample): I often get a letter from him.\n",
      "Target texts (one random sample): [start] Mara nyingi mimi hupokea barua kutoka kwake. [end]\n",
      "Source vectors (one random sample): tf.Tensor(\n",
      "[  5 282  88   6 485  34  43   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0], shape=(30,), dtype=int64)\n",
      "Target vectors (one random sample): tf.Tensor(\n",
      "[   2   46   69   48 7261  273   36  219    3    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0], shape=(31,), dtype=int64)\n",
      "Source decoded texts (one random sample): i often get a letter from him                        \n",
      "Target decoded texts (one random sample): [start] mara nyingi mimi hupokea barua kutoka kwake [end]                       \n"
     ]
    }
   ],
   "source": [
    "# display a random sample before and after vectorization just to test the vectorization\n",
    "random_sample = random.randint(0, len(train_df))\n",
    "print(\"Source texts (one random sample):\", train_source_texts[random_sample])\n",
    "print(\"Target texts (one random sample):\", train_target_texts[random_sample])\n",
    "print(\"Source vectors (one random sample):\", source_vectorization(train_source_texts[random_sample]))\n",
    "print(\"Target vectors (one random sample):\", target_vectorization(train_target_texts[random_sample]))\n",
    "\n",
    "# display the decoding of the vectorized text (from vector back to text) just to test the vectorization\n",
    "source_decoded_text = ''\n",
    "for i in range(len(source_vectorization(train_source_texts[random_sample]))):\n",
    "    source_decoded_text += source_vectorization.get_vocabulary()[source_vectorization(train_source_texts[random_sample])[i]] + ' '\n",
    "print(\"Source decoded texts (one random sample):\", source_decoded_text)\n",
    "\n",
    "target_decoded_text = ''\n",
    "for i in range(len(target_vectorization(train_target_texts[random_sample]))):\n",
    "    target_decoded_text += target_vectorization.get_vocabulary()[target_vectorization(train_target_texts[random_sample])[i]] + ' '\n",
    "print(\"Target decoded texts (one random sample):\", target_decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T22:20:12.119089Z",
     "iopub.status.busy": "2025-02-23T22:20:12.118836Z",
     "iopub.status.idle": "2025-02-23T22:20:13.027603Z",
     "shell.execute_reply": "2025-02-23T22:20:13.026676Z",
     "shell.execute_reply.started": "2025-02-23T22:20:12.119064Z"
    },
    "papermill": {
     "duration": 0.658519,
     "end_time": "2024-03-24T02:43:01.682143",
     "exception": false,
     "start_time": "2024-03-24T02:43:01.023624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source vectors (shape): (139270, 30)\n",
      "Target vectors (shape): (139270, 31)\n"
     ]
    }
   ],
   "source": [
    "# display the shape of our vectorized data\n",
    "train_source_vectors = source_vectorization(train_source_texts)\n",
    "train_target_vectors = target_vectorization(train_target_texts)\n",
    "print(\"Source vectors (shape):\", train_source_vectors.shape)\n",
    "print(\"Target vectors (shape):\", train_target_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012647,
     "end_time": "2024-03-24T02:43:01.73358",
     "exception": false,
     "start_time": "2024-03-24T02:43:01.720933",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Positional Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T22:20:13.028710Z",
     "iopub.status.busy": "2025-02-23T22:20:13.028476Z",
     "iopub.status.idle": "2025-02-23T22:20:13.035972Z",
     "shell.execute_reply": "2025-02-23T22:20:13.035031Z",
     "shell.execute_reply.started": "2025-02-23T22:20:13.028685Z"
    },
    "papermill": {
     "duration": 0.024552,
     "end_time": "2024-03-24T02:43:01.796276",
     "exception": false,
     "start_time": "2024-03-24T02:43:01.771724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(keras.layers.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = keras.layers.Embedding(input_dim=input_dim, output_dim=output_dim) # token embedding layer\n",
    "        self.position_embeddings = keras.layers.Embedding(input_dim=sequence_length, output_dim=output_dim) # position embedding layer\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        embedded_tokens = self.token_embeddings(inputs) # embed the tokens\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1) # create the positional information\n",
    "        embedded_positions = self.position_embeddings(positions) # embed the positions \n",
    "        return embedded_tokens + embedded_positions # add the token and position embeddings to create the positional embeddings\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return keras.ops.not_equal(inputs, 0)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(PositionalEmbedding, self).get_config()\n",
    "        config.update({\n",
    "            \"input_dim\": self.input_dim,\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T22:20:13.037297Z",
     "iopub.status.busy": "2025-02-23T22:20:13.037029Z",
     "iopub.status.idle": "2025-02-23T22:20:19.116024Z",
     "shell.execute_reply": "2025-02-23T22:20:19.115082Z",
     "shell.execute_reply.started": "2025-02-23T22:20:13.037255Z"
    },
    "papermill": {
     "duration": 4.564727,
     "end_time": "2024-03-24T02:43:06.373884",
     "exception": false,
     "start_time": "2024-03-24T02:43:01.809157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source texts (one random sample): Grasshoppers are seasonal insects.\n",
      "Target texts (one random sample): [start] Grasshoppers ni wadudu wa msimu. [end]\n",
      "Source vectors (one random sample): tf.Tensor(\n",
      "[ 8174    18 11712  5769     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0], shape=(30,), dtype=int64)\n",
      "Target vectors (one random sample): tf.Tensor(\n",
      "[    2 19091     8  3094     7   916     3     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0], shape=(31,), dtype=int64)\n",
      "Source embedded vectors (one random sample): tf.Tensor(\n",
      "[[-0.01866499  0.00616622 -0.05402397 ... -0.08396909 -0.03312936\n",
      "   0.06532638]\n",
      " [ 0.04037527 -0.07929007 -0.01828209 ... -0.04480408  0.00403329\n",
      "   0.04680081]\n",
      " [-0.05860395 -0.04521805 -0.08772665 ... -0.01408411  0.0130448\n",
      "   0.00291384]\n",
      " ...\n",
      " [ 0.02281722  0.07147868  0.0247016  ... -0.02860707  0.02992765\n",
      "   0.01600885]\n",
      " [-0.05146397  0.06364115  0.03920709 ... -0.04723538 -0.02731901\n",
      "   0.0136022 ]\n",
      " [ 0.00928311 -0.00020399  0.02835008 ...  0.00173945 -0.06481121\n",
      "  -0.04424887]], shape=(30, 256), dtype=float32)\n",
      "Target embedded vectors (one random sample): tf.Tensor(\n",
      "[[ 0.06299273  0.05230936 -0.0025637  ... -0.08196044  0.02282777\n",
      "  -0.03021208]\n",
      " [ 0.00938365  0.04577161  0.02821214 ...  0.02656137 -0.03556116\n",
      "   0.08888407]\n",
      " [-0.01463448 -0.05828308  0.02448035 ...  0.02182658 -0.02070991\n",
      "  -0.02475784]\n",
      " ...\n",
      " [ 0.04198375  0.01236689 -0.08257329 ... -0.02628219  0.00835415\n",
      "  -0.02693857]\n",
      " [ 0.08617818 -0.03730119 -0.07374662 ...  0.02778574  0.01080993\n",
      "   0.02004427]\n",
      " [ 0.07209317  0.02233265 -0.03698866 ...  0.00773014  0.02331314\n",
      "  -0.03295407]], shape=(30, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# display a random sample before and after embbeding just to test our class\n",
    "\n",
    "embed_dim = 256\n",
    "\n",
    "with tf.device('cpu:0'):\n",
    "    train_source_embedded = PositionalEmbedding(\n",
    "        sequence_length=sequence_length,\n",
    "        input_dim=max_tokens,\n",
    "        output_dim=embed_dim,\n",
    "        name=\"source_embedding\",\n",
    "    ) (train_source_vectors)\n",
    "\n",
    "    train_target_embedded = PositionalEmbedding(\n",
    "        sequence_length=sequence_length,\n",
    "        input_dim=max_tokens,\n",
    "        output_dim=embed_dim,\n",
    "        name=\"target_embedding\",\n",
    "    ) (train_source_vectors)\n",
    "\n",
    "    random_sample = random.randint(0, len(train_df))\n",
    "    print(\"Source texts (one random sample):\", train_source_texts[random_sample])\n",
    "    print(\"Target texts (one random sample):\", train_target_texts[random_sample])\n",
    "    print(\"Source vectors (one random sample):\", source_vectorization(train_source_texts[random_sample]))\n",
    "    print(\"Target vectors (one random sample):\", target_vectorization(train_target_texts[random_sample]))\n",
    "    print(\"Source embedded vectors (one random sample):\", train_source_embedded[random_sample])\n",
    "    print(\"Target embedded vectors (one random sample):\", train_target_embedded[random_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T22:20:19.117340Z",
     "iopub.status.busy": "2025-02-23T22:20:19.117058Z",
     "iopub.status.idle": "2025-02-23T22:20:19.122063Z",
     "shell.execute_reply": "2025-02-23T22:20:19.121131Z",
     "shell.execute_reply.started": "2025-02-23T22:20:19.117311Z"
    },
    "papermill": {
     "duration": 0.022335,
     "end_time": "2024-03-24T02:43:06.410932",
     "exception": false,
     "start_time": "2024-03-24T02:43:06.388597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source embedded vectors (shape): (139270, 30, 256)\n",
      "Target embedded vectors (shape): (139270, 30, 256)\n"
     ]
    }
   ],
   "source": [
    "# display the shape of our embedded data just to test the class\n",
    "print(\"Source embedded vectors (shape):\", train_source_embedded.shape)\n",
    "print(\"Target embedded vectors (shape):\", train_target_embedded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.0131,
     "end_time": "2024-03-24T02:43:06.437494",
     "exception": false,
     "start_time": "2024-03-24T02:43:06.424394",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T22:20:19.123387Z",
     "iopub.status.busy": "2025-02-23T22:20:19.123129Z",
     "iopub.status.idle": "2025-02-23T22:20:19.135234Z",
     "shell.execute_reply": "2025-02-23T22:20:19.134563Z",
     "shell.execute_reply.started": "2025-02-23T22:20:19.123361Z"
    },
    "papermill": {
     "duration": 0.025036,
     "end_time": "2024-03-24T02:43:06.555809",
     "exception": false,
     "start_time": "2024-03-24T02:43:06.530773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# credits to OpenAI for that one (https://github.com/openai/gpt-2/blob/master/src/model.py)\n",
    "\n",
    "def shape_list(x):\n",
    "    \"\"\"Deal with dynamic shape in tensorflow cleanly.\"\"\"\n",
    "    static = x.shape.as_list()\n",
    "    dynamic = tf.shape(x)\n",
    "    return [dynamic[i] if s is None else s for i, s in enumerate(static)]\n",
    "\n",
    "def attention_mask(nd, ns, *, dtype):\n",
    "    \"\"\"1's in the lower triangle, counting from the lower right corner.\n",
    "    Same as tf.matrix_band_part(tf.ones([nd, ns]), -1, ns-nd), but doesn't produce garbage on TPUs.\n",
    "    \"\"\"\n",
    "    i = tf.range(nd)[:,None]\n",
    "    j = tf.range(ns)\n",
    "    m = i >= j - ns + nd\n",
    "    return tf.cast(m, dtype)\n",
    "\n",
    "def mask_attn_weights(w):\n",
    "    # w has shape [batch, heads, dst_sequence, src_sequence], where information flows from src to dst.\n",
    "    _, _, nd, ns = shape_list(w)\n",
    "    b = attention_mask(nd, ns, dtype=w.dtype)\n",
    "    b = tf.reshape(b, [1, 1, nd, ns])\n",
    "    w = w*b - tf.cast(1e10, w.dtype)*(1-b)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T22:20:19.136896Z",
     "iopub.status.busy": "2025-02-23T22:20:19.136336Z",
     "iopub.status.idle": "2025-02-23T22:20:19.172190Z",
     "shell.execute_reply": "2025-02-23T22:20:19.171460Z",
     "shell.execute_reply.started": "2025-02-23T22:20:19.136861Z"
    },
    "papermill": {
     "duration": 0.090471,
     "end_time": "2024-03-24T02:43:06.659665",
     "exception": false,
     "start_time": "2024-03-24T02:43:06.569194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked attention weights: tf.Tensor(\n",
      "[[[[ 9.5843720e-01 -1.0000000e+10 -1.0000000e+10 -1.0000000e+10\n",
      "    -1.0000000e+10]\n",
      "   [ 3.3060622e-01  1.1689603e-01 -1.0000000e+10 -1.0000000e+10\n",
      "    -1.0000000e+10]\n",
      "   [ 2.8966928e-01  8.4028912e-01  9.9296749e-01 -1.0000000e+10\n",
      "    -1.0000000e+10]\n",
      "   [ 5.5471718e-01  8.4482193e-01  6.5454841e-02  1.6529107e-01\n",
      "    -1.0000000e+10]\n",
      "   [ 7.1845329e-01  2.6224947e-01  2.5937521e-01  2.3372722e-01\n",
      "     1.8005729e-01]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# display the causal masking of a random tensor just to test the function\n",
    "random_tensor = tf.random.uniform(shape=(1, 1, 5, 5), minval=0, maxval=1, dtype=tf.float32)\n",
    "print(\"Masked attention weights:\", mask_attn_weights(random_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T22:20:19.173287Z",
     "iopub.status.busy": "2025-02-23T22:20:19.173079Z",
     "iopub.status.idle": "2025-02-23T22:20:19.178202Z",
     "shell.execute_reply": "2025-02-23T22:20:19.177280Z",
     "shell.execute_reply.started": "2025-02-23T22:20:19.173265Z"
    },
    "papermill": {
     "duration": 0.022637,
     "end_time": "2024-03-24T02:43:06.750425",
     "exception": false,
     "start_time": "2024-03-24T02:43:06.727788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, use_causal_mask=False):\n",
    "    d_k = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scores = tf.matmul(q, k, transpose_b=True) # Matmul of Q and K\n",
    "    scaled_scores = scores / tf.math.sqrt(d_k) # Scale\n",
    "    if use_causal_mask:\n",
    "        scaled_scores = mask_attn_weights(scaled_scores) # Mask (opt.)\n",
    "    weights = tf.nn.softmax(scaled_scores, axis=-1) # SoftMax\n",
    "    output = tf.matmul(weights, v) # Matmul of SoftMax and V\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T22:20:19.179599Z",
     "iopub.status.busy": "2025-02-23T22:20:19.179268Z",
     "iopub.status.idle": "2025-02-23T22:20:27.849654Z",
     "shell.execute_reply": "2025-02-23T22:20:27.848710Z",
     "shell.execute_reply.started": "2025-02-23T22:20:19.179562Z"
    },
    "papermill": {
     "duration": 6.947731,
     "end_time": "2024-03-24T02:43:13.711689",
     "exception": false,
     "start_time": "2024-03-24T02:43:06.763958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled dot product attention (shape): (139270, 1, 30, 256)\n"
     ]
    }
   ],
   "source": [
    "# display the shape of our attention output just to test the function\n",
    "with tf.device('cpu:0'):\n",
    "    input = train_source_embedded\n",
    "    input = tf.expand_dims(input, axis=1)\n",
    "    print(\"Scaled dot product attention (shape):\", scaled_dot_product_attention(input, input, input, use_causal_mask=True).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013369,
     "end_time": "2024-03-24T02:43:13.738851",
     "exception": false,
     "start_time": "2024-03-24T02:43:13.725482",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Multi-Head Attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T22:20:27.851077Z",
     "iopub.status.busy": "2025-02-23T22:20:27.850798Z",
     "iopub.status.idle": "2025-02-23T22:20:27.860151Z",
     "shell.execute_reply": "2025-02-23T22:20:27.859341Z",
     "shell.execute_reply.started": "2025-02-23T22:20:27.851051Z"
    },
    "papermill": {
     "duration": 0.028579,
     "end_time": "2024-03-24T02:43:13.807406",
     "exception": false,
     "start_time": "2024-03-24T02:43:13.778827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, h, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.h = h\n",
    "        if embed_dim % h != 0:\n",
    "            raise ValueError(\n",
    "                f\"dimension of the embedding space = {embed_dim} should be divisible by number of heads = {h}\"\n",
    "            )\n",
    "        self.q_linear = keras.layers.Dense(embed_dim)\n",
    "        self.k_linear = keras.layers.Dense(embed_dim)\n",
    "        self.v_linear = keras.layers.Dense(embed_dim)\n",
    "        self.concat_linear = keras.layers.Dense(embed_dim)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, shape=(batch_size, -1, self.h, self.embed_dim // self.h))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def concat_heads(self, x, batch_size):\n",
    "        x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        return tf.reshape(x, (batch_size, -1, self.embed_dim))\n",
    "\n",
    "    def call(self, q, k, v, use_causal_mask=False):\n",
    "        batch_size = tf.shape(k)[0]\n",
    "        q = self.q_linear(q)\n",
    "        k = self.k_linear(k)\n",
    "        v = self.v_linear(v)\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "        attention = scaled_dot_product_attention(q, k, v, use_causal_mask)\n",
    "        concat = self.concat_heads(attention, batch_size)\n",
    "        concat = self.concat_linear(concat)\n",
    "        return concat\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(MultiHeadAttention, self).get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"h\": self.h,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016689,
     "end_time": "2024-03-24T02:43:13.837568",
     "exception": false,
     "start_time": "2024-03-24T02:43:13.820879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# The Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T22:20:27.861707Z",
     "iopub.status.busy": "2025-02-23T22:20:27.861303Z",
     "iopub.status.idle": "2025-02-23T22:20:27.880494Z",
     "shell.execute_reply": "2025-02-23T22:20:27.879593Z",
     "shell.execute_reply.started": "2025-02-23T22:20:27.861673Z"
    },
    "papermill": {
     "duration": 0.025125,
     "end_time": "2024-03-24T02:43:13.904122",
     "exception": false,
     "start_time": "2024-03-24T02:43:13.878997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerEncoder(keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.layer_norm_1 = keras.layers.LayerNormalization()\n",
    "        self.layer_norm_2 = keras.layers.LayerNormalization()\n",
    "        self.global_self_attention = MultiHeadAttention(embed_dim=embed_dim, h=num_heads)\n",
    "        self.feed_forward = keras.Sequential(\n",
    "            [keras.layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             keras.layers.Dense(embed_dim),]\n",
    "        )\n",
    "        \n",
    "    def call(self, x):\n",
    "        # Post layer normalization + residual connections\n",
    "        x = self.layer_norm_1(x + self.global_self_attention(q=x, k=x, v=x))\n",
    "        x = self.layer_norm_2(x + self.feed_forward(x))\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013295,
     "end_time": "2024-03-24T02:43:13.930868",
     "exception": false,
     "start_time": "2024-03-24T02:43:13.917573",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# The Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T22:20:27.881875Z",
     "iopub.status.busy": "2025-02-23T22:20:27.881586Z",
     "iopub.status.idle": "2025-02-23T22:20:27.894040Z",
     "shell.execute_reply": "2025-02-23T22:20:27.893301Z",
     "shell.execute_reply.started": "2025-02-23T22:20:27.881846Z"
    },
    "papermill": {
     "duration": 0.029098,
     "end_time": "2024-03-24T02:43:14.005434",
     "exception": false,
     "start_time": "2024-03-24T02:43:13.976336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerDecoder(keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.causal_self_attention = MultiHeadAttention(embed_dim=embed_dim, h=num_heads)\n",
    "        self.cross_attention = MultiHeadAttention(embed_dim=embed_dim, h=num_heads)\n",
    "        self.feed_forward = keras.Sequential(\n",
    "            [keras.layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             keras.layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layer_norm_1 = keras.layers.LayerNormalization()\n",
    "        self.layer_norm_2 = keras.layers.LayerNormalization()\n",
    "        self.layer_norm_3 = keras.layers.LayerNormalization()\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, x, context):\n",
    "        # Post layer normalization + residual connections\n",
    "        x = self.layer_norm_1(x + self.causal_self_attention(q=x, k=x, v=x, use_causal_mask=True))\n",
    "        x = self.layer_norm_2(x + self.cross_attention(q=x, k=context, v=context))\n",
    "        x = self.layer_norm_3(x + self.feed_forward(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE TRANSFORMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T22:20:27.895460Z",
     "iopub.status.busy": "2025-02-23T22:20:27.895118Z",
     "iopub.status.idle": "2025-02-23T22:20:28.280698Z",
     "shell.execute_reply": "2025-02-23T22:20:28.279546Z",
     "shell.execute_reply.started": "2025-02-23T22:20:27.895402Z"
    },
    "papermill": {
     "duration": 0.436775,
     "end_time": "2024-03-24T02:43:14.509572",
     "exception": false,
     "start_time": "2024-03-24T02:43:14.072797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "def format_dataset(source, target):\n",
    "    source_vectors = source_vectorization(source)\n",
    "    target_vectors = target_vectorization(target)\n",
    "    return ({\n",
    "        \"source\": source_vectors, # encoder_inputs\n",
    "        \"target\": target_vectors[:, :-1], # decoder_inputs (truncate by 1 to keep it at the same length as decoder_outputs, which is shifted right by 1).\n",
    "    }, target_vectors[:, 1:]) # decoder_outputs\n",
    "\n",
    "def make_dataset(df):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((df[\"source\"].values, df[\"target\"].values))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
    "    return dataset.shuffle(2048).prefetch(16).cache()\n",
    "\n",
    "train_ds = make_dataset(train_df)\n",
    "val_ds = make_dataset(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T22:20:28.282183Z",
     "iopub.status.busy": "2025-02-23T22:20:28.281846Z",
     "iopub.status.idle": "2025-02-23T22:20:28.970420Z",
     "shell.execute_reply": "2025-02-23T22:20:28.969465Z",
     "shell.execute_reply.started": "2025-02-23T22:20:28.282145Z"
    },
    "papermill": {
     "duration": 0.625052,
     "end_time": "2024-03-24T02:43:15.148816",
     "exception": false,
     "start_time": "2024-03-24T02:43:14.523764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Inputs: (64, 30)\n",
      "Decoder Inputs: (64, 30)\n",
      "Decoder Outputs: (64, 30)\n"
     ]
    }
   ],
   "source": [
    "# display the shape of the first batch of data in the dataset just to see what it looks like\n",
    "for batch in train_ds.take(1):\n",
    "    print(\"Encoder Inputs:\", batch[0][\"source\"].shape)\n",
    "    print(\"Decoder Inputs:\", batch[0][\"target\"].shape)\n",
    "    print(\"Decoder Outputs:\", batch[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T22:20:28.972355Z",
     "iopub.status.busy": "2025-02-23T22:20:28.971732Z",
     "iopub.status.idle": "2025-02-23T22:20:29.743095Z",
     "shell.execute_reply": "2025-02-23T22:20:29.742184Z",
     "shell.execute_reply.started": "2025-02-23T22:20:28.972313Z"
    },
    "papermill": {
     "duration": 1.08639,
     "end_time": "2024-03-24T02:43:16.276065",
     "exception": false,
     "start_time": "2024-03-24T02:43:15.189675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'transformer_encoder' (of type TransformerEncoder) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'transformer_decoder' (of type TransformerDecoder) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 512 # dimension of the embedding space\n",
    "dense_dim = 2048 # dimension of the feed forward network (a rule of thumb is to use 4 times the size of the embeddings)\n",
    "num_heads = 8\n",
    "\n",
    "# the transformer body\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"source\")\n",
    "x = PositionalEmbedding(sequence_length, max_tokens, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"target\")\n",
    "x = PositionalEmbedding(sequence_length, max_tokens, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
    "\n",
    "# the transformer head\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "decoder_outputs = keras.layers.Dense(max_tokens, activation=\"softmax\")(x)\n",
    "\n",
    "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013541,
     "end_time": "2024-03-24T02:43:16.303588",
     "exception": false,
     "start_time": "2024-03-24T02:43:16.290047",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training the Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T22:20:29.744987Z",
     "iopub.status.busy": "2025-02-23T22:20:29.744309Z",
     "iopub.status.idle": "2025-02-23T22:20:29.749111Z",
     "shell.execute_reply": "2025-02-23T22:20:29.748153Z",
     "shell.execute_reply.started": "2025-02-23T22:20:29.744943Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T22:20:29.750485Z",
     "iopub.status.busy": "2025-02-23T22:20:29.750195Z",
     "iopub.status.idle": "2025-02-23T22:20:29.758073Z",
     "shell.execute_reply": "2025-02-23T22:20:29.757320Z",
     "shell.execute_reply.started": "2025-02-23T22:20:29.750452Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "if not hasattr(tf.keras.backend, \"convert_to_numpy\"):\n",
    "    tf.keras.backend.convert_to_numpy = lambda x: x.numpy() if hasattr(x, \"numpy\") else x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-02-23T22:20:29.759696Z",
     "iopub.status.busy": "2025-02-23T22:20:29.759307Z",
     "iopub.status.idle": "2025-02-23T22:20:42.026597Z",
     "shell.execute_reply": "2025-02-23T22:20:42.025526Z",
     "shell.execute_reply.started": "2025-02-23T22:20:29.759656Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.16.1)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (70.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.62.2)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.8.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.11.0)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.3/615.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.8.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T22:20:42.029171Z",
     "iopub.status.busy": "2025-02-23T22:20:42.028238Z",
     "iopub.status.idle": "2025-02-23T22:20:42.034387Z",
     "shell.execute_reply": "2025-02-23T22:20:42.033599Z",
     "shell.execute_reply.started": "2025-02-23T22:20:42.029122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.16.1\n",
      "Keras Version: 3.3.3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print(\"Keras Version:\", keras.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T22:20:42.040390Z",
     "iopub.status.busy": "2025-02-23T22:20:42.039839Z",
     "iopub.status.idle": "2025-02-23T22:20:44.299878Z",
     "shell.execute_reply": "2025-02-23T22:20:44.298923Z",
     "shell.execute_reply.started": "2025-02-23T22:20:42.040351Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: keras 3.3.3\n",
      "Uninstalling keras-3.3.3:\n",
      "  Successfully uninstalled keras-3.3.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall keras -y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T22:20:44.301565Z",
     "iopub.status.busy": "2025-02-23T22:20:44.301236Z",
     "iopub.status.idle": "2025-02-23T22:56:46.838149Z",
     "shell.execute_reply": "2025-02-23T22:56:46.837434Z",
     "shell.execute_reply.started": "2025-02-23T22:20:44.301533Z"
    },
    "papermill": {
     "duration": 2419.625943,
     "end_time": "2024-03-24T03:23:35.943225",
     "exception": false,
     "start_time": "2024-03-24T02:43:16.317282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'multi_head_attention' (of type MultiHeadAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'multi_head_attention_1' (of type MultiHeadAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1740349249.827100      88 service.cc:145] XLA service 0x7b7b88003260 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1740349249.827179      88 service.cc:153]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "W0000 00:00:1740349250.133347      88 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   2/2177\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:22\u001b[0m 66ms/step - accuracy: 0.1704 - loss: 9.6350       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1740349256.360691      88 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1274/2177\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m48s\u001b[0m 54ms/step - accuracy: 0.7649 - loss: 1.9341"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1740349325.642561      88 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2177/2177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7792 - loss: 1.7578"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1740349378.821622      87 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "W0000 00:00:1740349381.343061      89 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2177/2177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 62ms/step - accuracy: 0.7792 - loss: 1.7577 - val_accuracy: 0.8453 - val_loss: 1.0444 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m2177/2177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 57ms/step - accuracy: 0.8431 - loss: 1.0848 - val_accuracy: 0.8636 - val_loss: 0.8896 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m2177/2177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 57ms/step - accuracy: 0.8601 - loss: 0.9152 - val_accuracy: 0.8697 - val_loss: 0.8374 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m2177/2177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 58ms/step - accuracy: 0.8716 - loss: 0.8111 - val_accuracy: 0.8734 - val_loss: 0.8044 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m2177/2177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 58ms/step - accuracy: 0.8804 - loss: 0.7373 - val_accuracy: 0.8757 - val_loss: 0.8044 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m2177/2177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 59ms/step - accuracy: 0.8872 - loss: 0.6824 - val_accuracy: 0.8768 - val_loss: 0.8023 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m2177/2177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 58ms/step - accuracy: 0.8933 - loss: 0.6369 - val_accuracy: 0.8776 - val_loss: 0.8169 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m2177/2177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 58ms/step - accuracy: 0.8985 - loss: 0.5984 - val_accuracy: 0.8780 - val_loss: 0.8276 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m2177/2177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 58ms/step - accuracy: 0.9032 - loss: 0.5651 - val_accuracy: 0.8786 - val_loss: 0.8296 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m2177/2177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 59ms/step - accuracy: 0.9168 - loss: 0.4736 - val_accuracy: 0.8891 - val_loss: 0.7456 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m2177/2177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 58ms/step - accuracy: 0.9297 - loss: 0.3902 - val_accuracy: 0.8896 - val_loss: 0.7425 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m2177/2177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 58ms/step - accuracy: 0.9352 - loss: 0.3556 - val_accuracy: 0.8899 - val_loss: 0.7457 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m2177/2177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 57ms/step - accuracy: 0.9392 - loss: 0.3298 - val_accuracy: 0.8898 - val_loss: 0.7502 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m2177/2177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 58ms/step - accuracy: 0.9426 - loss: 0.3090 - val_accuracy: 0.8898 - val_loss: 0.7556 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m2177/2177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 58ms/step - accuracy: 0.9454 - loss: 0.2929 - val_accuracy: 0.8904 - val_loss: 0.7518 - learning_rate: 1.0000e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m2177/2177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 58ms/step - accuracy: 0.9465 - loss: 0.2868 - val_accuracy: 0.8905 - val_loss: 0.7514 - learning_rate: 1.0000e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m2177/2177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 58ms/step - accuracy: 0.9471 - loss: 0.2834 - val_accuracy: 0.8906 - val_loss: 0.7521 - learning_rate: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "transformer.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "EPOCHS = 50\n",
    "checkpoint_filepath = '/tmp/checkpoint.weights.h5'\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.1,\n",
    "        patience=3,\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=6,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_best_only=True\n",
    "    ),\n",
    "]\n",
    "    \n",
    "transformer.fit(train_ds, \n",
    "                epochs=EPOCHS, \n",
    "                callbacks=callbacks_list,\n",
    "                validation_data=val_ds)\n",
    "\n",
    "transformer.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # After training and loading the best weights:\n",
    "# transformer.load_weights(checkpoint_filepath)\n",
    "\n",
    "# # Save the entire model (architecture + weights + optimizer state)\n",
    "# transformer.save(\"transformer_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T23:09:55.257024Z",
     "iopub.status.busy": "2025-02-23T23:09:55.256653Z",
     "iopub.status.idle": "2025-02-23T23:09:56.065252Z",
     "shell.execute_reply": "2025-02-23T23:09:56.064106Z",
     "shell.execute_reply.started": "2025-02-23T23:09:55.256991Z"
    }
   },
   "outputs": [],
   "source": [
    "# transformer.save(\"transformer_model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 3.368994,
     "end_time": "2024-03-24T03:23:42.607524",
     "exception": false,
     "start_time": "2024-03-24T03:23:39.23853",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Testing the Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 3.342189,
     "end_time": "2024-03-24T03:23:49.305977",
     "exception": false,
     "start_time": "2024-03-24T03:23:45.963788",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's translate a few random test sentences with our newly-trained Transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T23:10:08.850842Z",
     "iopub.status.busy": "2025-02-23T23:10:08.850182Z",
     "iopub.status.idle": "2025-02-23T23:10:32.743593Z",
     "shell.execute_reply": "2025-02-23T23:10:32.742647Z",
     "shell.execute_reply.started": "2025-02-23T23:10:08.850806Z"
    },
    "papermill": {
     "duration": 27.32186,
     "end_time": "2024-03-24T03:24:19.895885",
     "exception": false,
     "start_time": "2024-03-24T03:23:52.574025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tom looked at the painting on the wall.\n",
      "[start] tom alionekana uchoraji kwenye ukuta [end]\n",
      "\n",
      "I have a black cat.\n",
      "[start] nina paka mweusi [end]\n",
      "\n",
      "How long have you been dating?\n",
      "[start] umekuwa [UNK] kwa muda gani [end]\n",
      "\n",
      "Tom isn't as fast as i am.\n",
      "[start] tom hana haraka kama mimi [end]\n",
      "\n",
      "Truly, you o muhammad saw are one of the messengers,.\n",
      "[start] hakika wewe ni mmoja wao mitume [end]\n",
      "\n",
      "The lights aren't on.\n",
      "[start] taa ziko juu [end]\n",
      "\n",
      "In this way we enter upon the path.\n",
      "[start] kwa njia hii [UNK] kwenye njia [end]\n",
      "\n",
      "All aboard!\n",
      "[start] ndani yote [end]\n",
      "\n",
      "Encourage your friend to get help.\n",
      "[start] kumtia rafiki yako kupata msaada [end]\n",
      "\n",
      "Maybe he was trying to tell them something by showing it.\n",
      "[start] labda alikuwa akijaribu kuwaambia kitu kwa [UNK] [end]\n",
      "\n",
      "Topic the end of the world?\n",
      "[start] mada mwisho wa ulimwengu [end]\n",
      "\n",
      "Woocs ...\n",
      "[start] [UNK] [end]\n",
      "\n",
      "The hunters got up before dawn.\n",
      "[start] [UNK] kabla ya alfajiri [end]\n",
      "\n",
      "Tom got stuck in traffic.\n",
      "[start] tom alikwama kwenye trafiki [end]\n",
      "\n",
      "I'll tell you why.\n",
      "[start] nitakuambia kwanini [end]\n",
      "\n",
      "I anticipated trouble.\n",
      "[start] nilitarajia shida [end]\n",
      "\n",
      "She left me simply because i had a small income.\n",
      "[start] aliondoka kwa sababu nilikuwa na mapato madogo [end]\n",
      "\n",
      "There is little hope that she will come on time.\n",
      "[start] kuna matumaini kidogo kwamba atakuja kwa wakati [end]\n",
      "\n",
      "How long are we supposed to keep this up?\n",
      "[start] tunapaswa kukaa muda gani hadi hii [end]\n",
      "\n",
      "Did the dishwasher work?\n",
      "[start] je mashine ya kuosha vyombo vya kuosha vyombo vya kuosha vyombo vya habari vya kuosha vyombo vya kuosha vya kuosha vyombo vya habari vya habari vya kuosha mikono kwa mikono\n",
      "\n",
      "We heard a loud explosion.\n",
      "[start] tulisikia sauti kubwa [end]\n",
      "\n",
      "That's the whole story.\n",
      "[start] hiyo ndiyo hadithi nzima [end]\n",
      "\n",
      "I have an ear infection.\n",
      "[start] nina sikio la maambukizi [end]\n",
      "\n",
      "I heard what happened.\n",
      "[start] nilisikia kilichotokea [end]\n",
      "\n",
      "...it is quite clear that dr wilbrod slaa's decision to run as a presidential candidate has tilted the balance of power.\n",
      "[start] ni wazi kabisa kuwa dk [UNK] [UNK] [UNK] [UNK] mgombea urais ana uwezo wa rais wa rais wa rais wa mamlaka [end]\n",
      "\n",
      "This book will be very useful to us.\n",
      "[start] kitabu hiki kitakuwa na manufaa sana kwetu [end]\n",
      "\n",
      "He was covered all over with white paint.\n",
      "[start] [UNK] yote [UNK] rangi nyeupe [end]\n",
      "\n",
      "I'll be at home in the morning.\n",
      "[start] nitakuwa nyumbani asubuhi [end]\n",
      "\n",
      "After the end of this creation age death and the grave will not exist.\n",
      "[start] baada ya mwisho wa uumbaji huu na kifo [UNK] kaburi [UNK] [end]\n",
      "\n",
      "He was left all alone in the woods.\n",
      "[start] aliachwa peke yake msituni [end]\n",
      "\n",
      "With the arrival of the industrial revolution, however, modern machinery was used to demolish what was left of the mountain in order to recover the precious ore that still remained.\n",
      "[start] pamoja na mapinduzi ya viwanda ya viwanda hata hivyo [UNK] ya kisasa [UNK] mlima wa kushoto kile ambacho kilikuwa [UNK] kwenye mlima wa [UNK] wa [UNK] kuwa [UNK] [end]\n",
      "\n",
      "There should be equal treatment for both men and women.\n",
      "[start] kuna matibabu sawa kwa wanaume na wanawake na wanaume [end]\n",
      "\n",
      "Since when do you have a problem with the death penalty?\n",
      "[start] kwa kuwa una shida na adhabu ya kifo [end]\n",
      "\n",
      "Now there is only the un peacekeeping forces stopping nkunda's rebels from taking goma.\n",
      "[start] sasa kuna vikosi pekee ya umoja wa mataifa [UNK] waasi [UNK] waasi [UNK] [end]\n",
      "\n",
      "He came to japan two years ago.\n",
      "[start] alikuja japan miaka miwili iliyopita [end]\n",
      "\n",
      "I like to study foreign languages.\n",
      "[start] ninapenda kusoma lugha za kigeni [end]\n",
      "\n",
      "High quality,top service. we devote to be your industrial manufactuding solutions!\n",
      "[start] huduma ya juu ya [UNK] kwa kutumia suluhisho za [UNK] yako ya [UNK] [end]\n",
      "\n",
      "I was struck by lightning.\n",
      "[start] [UNK] na radi [end]\n",
      "\n",
      "I still think we should have invited james to go with us.\n",
      "[start] bado nadhani tunapaswa kualikwa pamoja nasi [end]\n",
      "\n",
      "I started to learn english with the aim of becoming a teacher.\n",
      "[start] nilianza kujifunza kiingereza pamoja na mwalimu wa kuwa mwalimu [end]\n",
      "\n",
      "It seems like the cat caught the scent of a mouse.\n",
      "[start] inaonekana paka [UNK] na panya wa panya [end]\n",
      "\n",
      "Except with the saying, if allah will! and remember your lord when you forget and say it may be that my lord guides me unto a nearer way of truth than this.\n",
      "[start] isipo kuwa mwenyezi mungu ikiwa mola wenu mlezi alipo sema [UNK] na [UNK] [end]\n",
      "\n",
      "When i was a child, i was always drinking milk.\n",
      "[start] nilipokuwa mtoto nilikuwa nikinywa maziwa kila wakati [end]\n",
      "\n",
      "I was reading a book while walking.\n",
      "[start] nilikuwa nasoma kitabu huku akitembea [end]\n",
      "\n",
      "And one of the elders saith unto to me, weep not behold, the lion of the tribe of juda, the root of david, hath prevailed to open the book . . . and in the midst of elders, stood a lamb as it had been slain, having seven horns and seven eyes. . .\n",
      "[start] na mmoja wa wazee [UNK] [UNK] [UNK] [UNK] wa kabila la daudi kabila la daudi [UNK] na daudi [UNK] na [UNK] [end]\n",
      "\n",
      "Shenzhen city.\n",
      "[start] shenzhen jiji [end]\n",
      "\n",
      "And all of this is also true of god.\n",
      "[start] na haya yote pia ni kweli wa mungu [end]\n",
      "\n",
      "I never meant to put you in any danger.\n",
      "[start] sikuwahi kutaka kuweka hatari yoyote [end]\n",
      "\n",
      "Candidates are assessed on the basis of fifty points for subparagraph a and ten points for each of subparagraphs b to e.\n",
      "[start] wagombea [UNK] kwa msingi wa hamsini kwa pointi hamsini na [UNK] kwa kila moja ya [UNK] ya [UNK] [UNK] b e [end]\n",
      "\n",
      "Dgb.\n",
      "[start] [UNK] [end]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_vocab = target_vectorization.get_vocabulary()\n",
    "target_index_lookup = dict(zip(range(len(target_vocab)), target_vocab))\n",
    "max_decoded_sentence_length = 30\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = target_vectorization(\n",
    "            [decoded_sentence])[:, :-1]\n",
    "        predictions = transformer(\n",
    "            [tokenized_input_sentence, tokenized_target_sentence])\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = target_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "# let's translate 50 random sentences\n",
    "for i in range(50):\n",
    "    random_index = np.random.randint(0, len(test_df))\n",
    "    input_sentence = test_df[\"source\"].iloc[random_index]\n",
    "    print(input_sentence)\n",
    "    print(decode_sequence(input_sentence))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Its getting good prediction** against test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing againt new data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T23:10:41.355744Z",
     "iopub.status.busy": "2025-02-23T23:10:41.355368Z",
     "iopub.status.idle": "2025-02-23T23:10:41.378772Z",
     "shell.execute_reply": "2025-02-23T23:10:41.378056Z",
     "shell.execute_reply.started": "2025-02-23T23:10:41.355710Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English sentence</th>\n",
       "      <th>Swahili Translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In 1983, two separate research groups led by R...</td>\n",
       "      <td>Mnamo 1983, vikundi viwili tofauti vya watafit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In the early days, the CDC did not have an off...</td>\n",
       "      <td>Katika siku za kwanza, kituo hicho hakikuwa na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The chance of quitting is improved with social...</td>\n",
       "      <td>Uwezekano wa kukoma huendelezwa kwa usaidizi w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Both strains of the tuberculosis bacteria shar...</td>\n",
       "      <td>Wote Matatizo ya bakteria kifua kikuu kushirik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Products with 60% to 95% alcohol by volume are...</td>\n",
       "      <td>Michanganyiko huwa na asilimia 60-95 za alikoh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    English sentence  \\\n",
       "0  In 1983, two separate research groups led by R...   \n",
       "1  In the early days, the CDC did not have an off...   \n",
       "2  The chance of quitting is improved with social...   \n",
       "3  Both strains of the tuberculosis bacteria shar...   \n",
       "4  Products with 60% to 95% alcohol by volume are...   \n",
       "\n",
       "                                 Swahili Translation  \n",
       "0  Mnamo 1983, vikundi viwili tofauti vya watafit...  \n",
       "1  Katika siku za kwanza, kituo hicho hakikuwa na...  \n",
       "2  Uwezekano wa kukoma huendelezwa kwa usaidizi w...  \n",
       "3  Wote Matatizo ya bakteria kifua kikuu kushirik...  \n",
       "4  Michanganyiko huwa na asilimia 60-95 za alikoh...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned test data\n",
    "test_df = pd.read_csv(\"/kaggle/input/test-en-to-swa-cleaned/test_en_to_swa_cleaned.csv\")\n",
    "\n",
    "# Inspect the first few rows to ensure the columns are correctly named\n",
    "test_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T23:10:45.440600Z",
     "iopub.status.busy": "2025-02-23T23:10:45.439891Z",
     "iopub.status.idle": "2025-02-23T23:21:13.470208Z",
     "shell.execute_reply": "2025-02-23T23:21:13.469483Z",
     "shell.execute_reply.started": "2025-02-23T23:10:45.440566Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'multi_head_attention' (of type MultiHeadAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'transformer_encoder' (of type TransformerEncoder) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'multi_head_attention_1' (of type MultiHeadAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'transformer_decoder' (of type TransformerDecoder) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: In 1983, two separate research groups led by Robert Gallo and Luc Montagnier declared that a novel retrovirus may have been infecting people with AIDS, and published their findings in the same issue of the journal Science. \n",
      "Prediction: katika [UNK] vikundi viwili tofauti na vikundi vya robert [UNK] na [UNK] [UNK] [UNK] [UNK] [UNK] kwamba riwaya ya [UNK] [UNK] [UNK] na [UNK] na [UNK] kwa sababu ya [UNK]\n",
      "Target: Mnamo 1983, vikundi viwili tofauti vya watafiti vilivyoongozwa na Robert Gallo na Luc Montagnier bila kutegemeana vilitangaza kuwa retrovirusi mpya ilikuwa ikiwaambukiza wagonjwa wa UKIMWI, hivyo wakachapisha matokeo yao katika jarida la Science. \n",
      "\n",
      "Input: In the early days, the CDC did not have an official name for the disease, often referring to it by way of the diseases that were associated with it, for example, lymphadenopathy, the disease after which the discoverers of HIV originally named the virus. \n",
      "Prediction: katika siku za mapema cdc [UNK] jina rasmi [UNK] kwa ugonjwa huo kwa njia ya ugonjwa huo kwa magonjwa ambayo [UNK] na magonjwa ambayo [UNK] na [UNK]\n",
      "Target: Katika siku za kwanza, kituo hicho hakikuwa na jina rasmi la ugonjwa huu, mara nyingi wakitumia majina ya magonjwa mengine yaliyohusishwa nao, kwa mfano, limfadenopathi, jina ambalo baadaye wavumbuzi wa VVU waliviita virusi hivi. \n",
      "\n",
      "Input: The chance of quitting is improved with social support, engagement in a smoking cessation program, and the use of medications such as nicotine replacement therapy, bupropion, or varenicline. \n",
      "Prediction: nafasi ya kuacha [UNK] na msaada wa kijamii kwa usaidizi katika mpango wa kuvuta sigara na dawa za kulevya na dawa za kulevya [UNK] wa [UNK] au uingizwaji wa [UNK]\n",
      "Target: Uwezekano wa kukoma huendelezwa kwa usaidizi wa kijamii, kuhusika katika mpango wa kukomesha uvutaji na kutumia tiba kama vile tiba ya kubadili nikotini, bupropion au varenicline. \n",
      "\n",
      "Input: Both strains of the tuberculosis bacteria share a common ancestor, which could have infected humans even before the Neolithic Revolution. \n",
      "Prediction: aina zote za kifua kikuu kikuu cha kawaida [UNK] ambayo [UNK] [UNK] [UNK] ni kwamba wanadamu [UNK] kabla hata mapinduzi\n",
      "Target: Wote Matatizo ya bakteria kifua kikuu kushiriki babu ya kawaida, ambayo ingeweza kuambukizwa binadamu kama mapema kama Mapinduzi Neolithic. \n",
      "\n",
      "Input: Products with 60% to 95% alcohol by volume are effective antiseptics. \n",
      "Prediction: bidhaa kwa [UNK] na [UNK] ya pombe kwa ufanisi\n",
      "Target: Michanganyiko huwa na asilimia 60-95 za alikoholi. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lists to hold the ground truth and model predictions\n",
    "references = []\n",
    "hypotheses = []\n",
    "\n",
    "# Loop over all test examples (or a sample of them)\n",
    "for index, row in test_df.iterrows():\n",
    "    # Assuming the CSV columns are named \"English sentence\" and \"Swahili Translation\"\n",
    "    input_sentence = row[\"English sentence\"]\n",
    "    true_translation = row[\"Swahili Translation\"]\n",
    "    \n",
    "    # Decode the translation using your model\n",
    "    predicted_sentence = decode_sequence(input_sentence)\n",
    "    \n",
    "    # Remove the special tokens \"[start]\" and \"[end]\" from the predicted sentence\n",
    "    predicted_sentence = predicted_sentence.replace(\"[start]\", \"\").replace(\"[end]\", \"\").strip()\n",
    "    true_translation_clean = true_translation.strip().lower()\n",
    "    \n",
    "    # Tokenize the sentences (here a simple split is used; feel free to use a more robust tokenizer)\n",
    "    predicted_tokens = predicted_sentence.split()\n",
    "    true_tokens = true_translation_clean.split()\n",
    "    \n",
    "    # Append to lists (note that BLEU expects a list of reference lists)\n",
    "    references.append([true_tokens])\n",
    "    hypotheses.append(predicted_tokens)\n",
    "    \n",
    "    # Optional: print a few examples\n",
    "    if index < 5:\n",
    "        print(\"Input:\", input_sentence)\n",
    "        print(\"Prediction:\", predicted_sentence)\n",
    "        print(\"Target:\", true_translation)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T23:21:13.471771Z",
     "iopub.status.busy": "2025-02-23T23:21:13.471497Z",
     "iopub.status.idle": "2025-02-23T23:21:14.707901Z",
     "shell.execute_reply": "2025-02-23T23:21:14.707083Z",
     "shell.execute_reply.started": "2025-02-23T23:21:13.471744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus BLEU Score: 0.05912423603224894\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "# Compute corpus-level BLEU score\n",
    "bleu_score = corpus_bleu(references, hypotheses)\n",
    "print(\"Corpus BLEU Score:\", bleu_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 3.291308,
     "end_time": "2024-03-24T03:24:26.461946",
     "exception": false,
     "start_time": "2024-03-24T03:24:23.170638",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Credits and stuff\n",
    "\n",
    "- https://arxiv.org/abs/1706.03762\n",
    "\n",
    "- https://www.tensorflow.org/text/tutorials/transformer\n",
    "\n",
    "- https://github.com/openai/gpt-2/blob/master/src/model.py\n",
    "\n",
    "- https://github.com/karpathy/minGPT/blob/master/mingpt/model.py\n",
    "\n",
    "- https://livebook.manning.com/book/deep-learning-with-python-second-edition/chapter-11\n",
    "\n",
    "    - https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/chapter11_part03_transformer.ipynb\n",
    "\n",
    "    - https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/chapter11_part04_sequence-to-sequence-learning.ipynb\n",
    "\n",
    "- https://www.oreilly.com/library/view/natural-language-processing/9781098136789/ch03.html\n",
    "\n",
    "    - https://github.com/nlp-with-transformers/notebooks/blob/main/03_transformer-anatomy.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 592212,
     "sourceId": 1067156,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6716358,
     "sourceId": 10817575,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6728192,
     "sourceId": 10834581,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 223923029,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2516.737775,
   "end_time": "2024-03-24T03:24:33.118324",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-24T02:42:36.380549",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
